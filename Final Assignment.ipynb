{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d9e7914",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center\">\n",
    "    <a href=\"https://skills.network/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkPY0220ENSkillsNetwork900-2022-01-01\" target=\"_blank\">\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\"  />\n",
    "    </a>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3297b8f-d940-495e-b617-311976f3374a",
   "metadata": {},
   "source": [
    "<h1>Extracting and Visualizing Stock Data</h1>\n",
    "<h2>Description</h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63757ca-0a1f-4a61-bd6c-3c25f234e7fb",
   "metadata": {},
   "source": [
    "Extracting essential data from a dataset and displaying it is a necessary part of data science; therefore individuals can make correct decisions based on the data. In this assignment, you will extract some stock data, you will then display this data in a graph.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a783a7-56d2-4e99-97cf-ea53bfc8aa81",
   "metadata": {},
   "source": [
    "<h2>Table of Contents</h2>\n",
    "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
    "    <ul>\n",
    "        <li>Define a Function that Makes a Graph</li>\n",
    "        <li>Question 1: Use yfinance to Extract Stock Data</li>\n",
    "        <li>Question 2: Use Webscraping to Extract Tesla Revenue Data</li>\n",
    "        <li>Question 3: Use yfinance to Extract Stock Data</li>\n",
    "        <li>Question 4: Use Webscraping to Extract GME Revenue Data</li>\n",
    "        <li>Question 5: Plot Tesla Stock Graph</li>\n",
    "        <li>Question 6: Plot GameStop Stock Graph</li>\n",
    "    </ul>\n",
    "<p>\n",
    "    Estimated Time Needed: <strong>30 min</strong></p>\n",
    "</div>\n",
    "\n",
    "<hr>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be6e0c97-5ff6-4c62-8123-c41697152060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting yfinance==0.1.67\n",
      "  Downloading yfinance-0.1.67-py2.py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: pandas>=0.24 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from yfinance==0.1.67) (1.3.5)\n",
      "Requirement already satisfied: requests>=2.20 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from yfinance==0.1.67) (2.28.1)\n",
      "Requirement already satisfied: lxml>=4.5.1 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from yfinance==0.1.67) (4.9.1)\n",
      "Collecting multitasking>=0.0.7\n",
      "  Downloading multitasking-0.0.11-py3-none-any.whl (8.5 kB)\n",
      "Requirement already satisfied: numpy>=1.15 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from yfinance==0.1.67) (1.21.6)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from pandas>=0.24->yfinance==0.1.67) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from pandas>=0.24->yfinance==0.1.67) (2022.6)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from requests>=2.20->yfinance==0.1.67) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from requests>=2.20->yfinance==0.1.67) (2022.9.24)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from requests>=2.20->yfinance==0.1.67) (1.26.13)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from requests>=2.20->yfinance==0.1.67) (3.4)\n",
      "Requirement already satisfied: six>=1.5 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas>=0.24->yfinance==0.1.67) (1.16.0)\n",
      "Installing collected packages: multitasking, yfinance\n",
      "Successfully installed multitasking-0.0.11 yfinance-0.1.67\n",
      "\n",
      "                  __    __    __    __\n",
      "                 /  \\  /  \\  /  \\  /  \\\n",
      "                /    \\/    \\/    \\/    \\\n",
      "███████████████/  /██/  /██/  /██/  /████████████████████████\n",
      "              /  / \\   / \\   / \\   / \\  \\____\n",
      "             /  /   \\_/   \\_/   \\_/   \\    o \\__,\n",
      "            / _/                       \\_____/  `\n",
      "            |/\n",
      "        ███╗   ███╗ █████╗ ███╗   ███╗██████╗  █████╗\n",
      "        ████╗ ████║██╔══██╗████╗ ████║██╔══██╗██╔══██╗\n",
      "        ██╔████╔██║███████║██╔████╔██║██████╔╝███████║\n",
      "        ██║╚██╔╝██║██╔══██║██║╚██╔╝██║██╔══██╗██╔══██║\n",
      "        ██║ ╚═╝ ██║██║  ██║██║ ╚═╝ ██║██████╔╝██║  ██║\n",
      "        ╚═╝     ╚═╝╚═╝  ╚═╝╚═╝     ╚═╝╚═════╝ ╚═╝  ╚═╝\n",
      "\n",
      "        mamba (0.15.3) supported by @QuantStack\n",
      "\n",
      "        GitHub:  https://github.com/mamba-org/mamba\n",
      "        Twitter: https://twitter.com/QuantStack\n",
      "\n",
      "█████████████████████████████████████████████████████████████\n",
      "\n",
      "\n",
      "Looking for: ['bs4==4.10.0']\n",
      "\n",
      "pkgs/r/linux-64          [<=>                 ] (00m:00s) \n",
      "pkgs/r/linux-64          [=>                ] (00m:00s) 495  B / ?? (3.15 KB/s)\n",
      "pkgs/r/linux-64          [=>                ] (00m:00s) 495  B / ?? (3.15 KB/s)\n",
      "pkgs/main/linux-64       [<=>                 ] (00m:00s) \n",
      "pkgs/r/linux-64          [=>                ] (00m:00s) 495  B / ?? (3.15 KB/s)\n",
      "pkgs/main/linux-64       [=>                ] (00m:00s) 648 KB / ?? (2.08 MB/s)\n",
      "pkgs/r/linux-64          [=>                ] (00m:00s) 495  B / ?? (3.15 KB/s)\n",
      "pkgs/main/linux-64       [=>                ] (00m:00s) 648 KB / ?? (2.08 MB/s)\n",
      "pkgs/main/noarch         [<=>                 ] (00m:00s) \n",
      "pkgs/r/linux-64          [=>                ] (00m:00s) 495  B / ?? (3.15 KB/s)\n",
      "pkgs/main/linux-64       [=>                ] (00m:00s) 648 KB / ?? (2.08 MB/s)\n",
      "pkgs/main/noarch         [=>                ] (00m:00s) 732 KB / ?? (2.35 MB/s)\n",
      "pkgs/r/linux-64          [<=>               ] (00m:00s) 495  B / ?? (3.15 KB/s)\n",
      "pkgs/main/linux-64       [=>                ] (00m:00s) 648 KB / ?? (2.08 MB/s)\n",
      "pkgs/main/noarch         [=>                ] (00m:00s) 732 KB / ?? (2.35 MB/s)\n",
      "pkgs/r/linux-64          [<=>               ] (00m:00s) 772 KB / ?? (2.48 MB/s)\n",
      "pkgs/main/linux-64       [=>                ] (00m:00s) 648 KB / ?? (2.08 MB/s)\n",
      "pkgs/main/noarch         [=>                ] (00m:00s) 732 KB / ?? (2.35 MB/s)\n",
      "pkgs/r/linux-64          [<=>               ] (00m:00s) 772 KB / ?? (2.48 MB/s)\n",
      "pkgs/main/linux-64       [=>                ] (00m:00s) 648 KB / ?? (2.08 MB/s)\n",
      "pkgs/main/noarch         [=>                ] (00m:00s) 732 KB / ?? (2.35 MB/s)\n",
      "pkgs/r/noarch            [<=>                 ] (00m:00s) \n",
      "pkgs/r/linux-64          [<=>               ] (00m:00s) 772 KB / ?? (2.48 MB/s)\n",
      "pkgs/main/linux-64       [=>                ] (00m:00s) 648 KB / ?? (2.08 MB/s)\n",
      "pkgs/main/noarch         [=>                ] (00m:00s) 732 KB / ?? (2.35 MB/s)\n",
      "pkgs/r/noarch            [=>                ] (00m:00s) 652 KB / ?? (2.10 MB/s)\n",
      "pkgs/r/linux-64          [<=>               ] (00m:00s) 772 KB / ?? (2.48 MB/s)\n",
      "pkgs/main/linux-64       [=>                ] (00m:00s) 648 KB / ?? (2.08 MB/s)\n",
      "pkgs/main/noarch         [<=>                 ] (00m:00s) Finalizing...\n",
      "pkgs/r/noarch            [=>                ] (00m:00s) 652 KB / ?? (2.10 MB/s)\n",
      "pkgs/r/linux-64          [<=>               ] (00m:00s) 772 KB / ?? (2.48 MB/s)\n",
      "pkgs/main/linux-64       [=>                ] (00m:00s) 648 KB / ?? (2.08 MB/s)\n",
      "pkgs/main/noarch         [<=>                 ] (00m:00s) Done\n",
      "pkgs/r/noarch            [=>                ] (00m:00s) 652 KB / ?? (2.10 MB/s)\n",
      "pkgs/main/noarch         [====================] (00m:00s) Done\n",
      "pkgs/r/linux-64          [<=>               ] (00m:00s) 772 KB / ?? (2.48 MB/s)\n",
      "pkgs/main/linux-64       [=>                ] (00m:00s) 648 KB / ?? (2.08 MB/s)\n",
      "pkgs/r/noarch            [=>                ] (00m:00s) 652 KB / ?? (2.10 MB/s)\n",
      "pkgs/r/linux-64          [ <=>                ] (00m:00s) Finalizing...\n",
      "pkgs/main/linux-64       [=>                ] (00m:00s) 648 KB / ?? (2.08 MB/s)\n",
      "pkgs/r/noarch            [=>                ] (00m:00s) 652 KB / ?? (2.10 MB/s)\n",
      "pkgs/r/linux-64          [ <=>                ] (00m:00s) Done\n",
      "pkgs/main/linux-64       [=>                ] (00m:00s) 648 KB / ?? (2.08 MB/s)\n",
      "pkgs/r/noarch            [=>                ] (00m:00s) 652 KB / ?? (2.10 MB/s)\n",
      "pkgs/r/linux-64          [====================] (00m:00s) Done\n",
      "pkgs/main/linux-64       [=>                ] (00m:00s) 648 KB / ?? (2.08 MB/s)\n",
      "pkgs/r/noarch            [=>                ] (00m:00s) 652 KB / ?? (2.10 MB/s)\n",
      "pkgs/main/linux-64       [<=>               ] (00m:00s) 648 KB / ?? (2.08 MB/s)\n",
      "pkgs/r/noarch            [=>                ] (00m:00s) 652 KB / ?? (2.10 MB/s)\n",
      "pkgs/main/linux-64       [ <=>                ] (00m:00s) 1 MB / ?? (2.67 MB/s)\n",
      "pkgs/r/noarch            [=>                ] (00m:00s) 652 KB / ?? (2.10 MB/s)\n",
      "pkgs/main/linux-64       [ <=>                ] (00m:00s) 1 MB / ?? (2.67 MB/s)\n",
      "pkgs/r/noarch            [<=>               ] (00m:00s) 652 KB / ?? (2.10 MB/s)\n",
      "pkgs/main/linux-64       [ <=>                ] (00m:00s) 1 MB / ?? (2.67 MB/s)\n",
      "pkgs/r/noarch            [ <=>                ] (00m:00s) 1 MB / ?? (2.57 MB/s)\n",
      "pkgs/main/linux-64       [ <=>                ] (00m:00s) 1 MB / ?? (2.67 MB/s)\n",
      "pkgs/r/noarch            [ <=>                ] (00m:00s) Finalizing...\n",
      "pkgs/main/linux-64       [ <=>                ] (00m:00s) 1 MB / ?? (2.67 MB/s)\n",
      "pkgs/r/noarch            [ <=>                ] (00m:00s) Done\n",
      "pkgs/r/noarch            [====================] (00m:00s) Done\n",
      "pkgs/main/linux-64       [ <=>                ] (00m:00s) 1 MB / ?? (2.67 MB/s)\n",
      "pkgs/main/linux-64       [  <=>               ] (00m:00s) 1 MB / ?? (2.67 MB/s)\n",
      "pkgs/main/linux-64       [  <=>               ] (00m:00s) 2 MB / ?? (3.49 MB/s)\n",
      "pkgs/main/linux-64       [   <=>              ] (00m:00s) 2 MB / ?? (3.49 MB/s)\n",
      "pkgs/main/linux-64       [   <=>              ] (00m:00s) 3 MB / ?? (3.71 MB/s)\n",
      "pkgs/main/linux-64       [    <=>             ] (00m:00s) 3 MB / ?? (3.71 MB/s)\n",
      "pkgs/main/linux-64       [    <=>             ] (00m:00s) 4 MB / ?? (3.91 MB/s)\n",
      "pkgs/main/linux-64       [     <=>            ] (00m:00s) 4 MB / ?? (3.91 MB/s)\n",
      "pkgs/main/linux-64       [     <=>            ] (00m:00s) 4 MB / ?? (4.05 MB/s)\n",
      "pkgs/main/linux-64       [     <=>            ] (00m:00s) Finalizing...\n",
      "pkgs/main/linux-64       [     <=>            ] (00m:01s) Done\n",
      "pkgs/main/linux-64       [====================] (00m:01s) Done\n",
      "\n",
      "Pinned packages:\n",
      "  - python 3.7.*\n",
      "\n",
      "\n",
      "Transaction\n",
      "\n",
      "  Prefix: /home/jupyterlab/conda/envs/python\n",
      "\n",
      "  Updating specs:\n",
      "\n",
      "   - bs4==4.10.0\n",
      "   - ca-certificates\n",
      "   - certifi\n",
      "   - openssl\n",
      "\n",
      "\n",
      "  Package               Version  Build           Channel                  Size\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "  Install:\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "\u001b[32m  + bs4            \u001b[00m      4.10.0  hd3eb1b0_0      pkgs/main/noarch        10 KB\n",
      "\n",
      "  Upgrade:\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "\u001b[31m  - ca-certificates\u001b[00m   2022.9.24  ha878542_0      installed                    \n",
      "\u001b[32m  + ca-certificates\u001b[00m  2023.01.10  h06a4308_0      pkgs/main/linux-64     120 KB\n",
      "\u001b[31m  - certifi        \u001b[00m   2022.9.24  pyhd8ed1ab_0    installed                    \n",
      "\u001b[32m  + certifi        \u001b[00m   2022.12.7  py37h06a4308_0  pkgs/main/linux-64     150 KB\n",
      "\u001b[31m  - openssl        \u001b[00m      1.1.1s  h0b41bf4_1      installed                    \n",
      "\u001b[32m  + openssl        \u001b[00m      1.1.1t  h7f8727e_0      pkgs/main/linux-64       4 MB\n",
      "\n",
      "  Downgrade:\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "\u001b[31m  - beautifulsoup4 \u001b[00m      4.11.1  pyha770c72_0    installed                    \n",
      "\u001b[32m  + beautifulsoup4 \u001b[00m      4.10.0  pyh06a4308_0    pkgs/main/noarch        85 KB\n",
      "\n",
      "  Summary:\n",
      "\n",
      "  Install: 1 packages\n",
      "  Upgrade: 3 packages\n",
      "  Downgrade: 1 packages\n",
      "\n",
      "  Total download: 4 MB\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "Downloading  [>                                        ] (00m:00s)   39.09 KB/s\n",
      "Extracting   [>                                                      ] (--:--) \n",
      "\u001b[2A\u001b[0KFinished bs4                                  (00m:00s)              10 KB     39 KB/s\n",
      "Downloading  [>                                        ] (00m:00s)   39.09 KB/s\n",
      "Extracting   [>                                                      ] (--:--) \n",
      "Downloading  [>                                        ] (00m:00s)   39.09 KB/s\n",
      "Extracting   [>                                                      ] (--:--) \n",
      "Downloading  [>                                        ] (00m:00s)   39.09 KB/s\n",
      "Extracting   [>                                                      ] (--:--) \n",
      "Downloading  [>                                        ] (00m:00s)  364.99 KB/s\n",
      "Extracting   [>                                                      ] (--:--) \n",
      "\u001b[2A\u001b[0KFinished beautifulsoup4                       (00m:00s)              85 KB    325 KB/s\n",
      "Downloading  [>                                        ] (00m:00s)  364.99 KB/s\n",
      "Extracting   [>                                                      ] (--:--) \n",
      "Downloading  [>                                        ] (00m:00s)  364.99 KB/s\n",
      "Extracting   [>                                                      ] (--:--) \n",
      "Downloading  [==>                                      ] (00m:00s)  824.68 KB/s\n",
      "Extracting   [>                                                      ] (--:--) \n",
      "\u001b[2A\u001b[0KFinished ca-certificates                      (00m:00s)             120 KB    462 KB/s\n",
      "Downloading  [==>                                      ] (00m:00s)  824.68 KB/s\n",
      "Extracting   [>                                                      ] (--:--) \n",
      "Downloading  [==>                                      ] (00m:00s)  824.68 KB/s\n",
      "Extracting   [>                                                      ] (--:--) \n",
      "Downloading  [===>                                     ] (00m:00s)    1.36 MB/s\n",
      "Extracting   [>                                                      ] (--:--) \n",
      "\u001b[2A\u001b[0KFinished certifi                              (00m:00s)             150 KB    576 KB/s\n",
      "Downloading  [===>                                     ] (00m:00s)    1.36 MB/s\n",
      "Extracting   [>                                                      ] (--:--) \n",
      "Downloading  [===>                                     ] (00m:00s)    1.36 MB/s\n",
      "Extracting   [>                                                      ] (--:--) \n",
      "Downloading  [===>                                     ] (00m:00s)    1.36 MB/s\n",
      "Extracting   [========>                                ] (00m:00s)        1 / 5\n",
      "Downloading  [===>                                     ] (00m:00s)    1.36 MB/s\n",
      "Extracting   [========>                                ] (00m:00s)        1 / 5\n",
      "Downloading  [===>                                     ] (00m:00s)    1.36 MB/s\n",
      "Extracting   [================>                        ] (00m:00s)        2 / 5\n",
      "Downloading  [===>                                     ] (00m:00s)    1.36 MB/s\n",
      "Extracting   [================>                        ] (00m:00s)        2 / 5\n",
      "Downloading  [===>                                     ] (00m:00s)    1.36 MB/s\n",
      "Extracting   [========================>                ] (00m:00s)        3 / 5\n",
      "Downloading  [===>                                     ] (00m:00s)    1.36 MB/s\n",
      "Extracting   [========================>                ] (00m:00s)        3 / 5\n",
      "Downloading  [===>                                     ] (00m:00s)    1.36 MB/s\n",
      "Extracting   [================================>        ] (00m:00s)        4 / 5\n",
      "Downloading  [======================>                  ] (00m:00s)    7.46 MB/s\n",
      "Extracting   [================================>        ] (00m:00s)        4 / 5\n",
      "Downloading  [======================>                  ] (00m:00s)    7.46 MB/s\n",
      "Extracting   [================================>        ] (00m:00s)        4 / 5\n",
      "Downloading  [=========================================] (00m:00s)   12.79 MB/s\n",
      "Extracting   [================================>        ] (00m:00s)        4 / 5\n",
      "\u001b[2A\u001b[0KFinished openssl                              (00m:00s)               4 MB     12 MB/s\n",
      "Downloading  [=========================================] (00m:00s)   12.79 MB/s\n",
      "Extracting   [================================>        ] (00m:00s)        4 / 5\n",
      "Downloading  [=========================================] (00m:00s)   12.79 MB/s\n",
      "Extracting   [================================>        ] (00m:00s)        4 / 5\n",
      "Downloading  [=========================================] (00m:00s)   12.79 MB/s\n",
      "Extracting   [================================>        ] (00m:00s)        4 / 5\n",
      "Downloading  [=========================================] (00m:00s)   12.79 MB/s\n",
      "Extracting   [=========================================] (00m:00s)        5 / 5\n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "Collecting nbformat==4.2.0\n",
      "  Downloading nbformat-4.2.0-py2.py3-none-any.whl (153 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.3/153.3 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: jupyter-core in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from nbformat==4.2.0) (4.12.0)\n",
      "Requirement already satisfied: traitlets>=4.1 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from nbformat==4.2.0) (5.6.0)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from nbformat==4.2.0) (4.17.3)\n",
      "Requirement already satisfied: ipython-genutils in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from nbformat==4.2.0) (0.2.0)\n",
      "Requirement already satisfied: importlib-resources>=1.4.0 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat==4.2.0) (5.10.1)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat==4.2.0) (22.1.0)\n",
      "Requirement already satisfied: typing-extensions in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat==4.2.0) (4.4.0)\n",
      "Requirement already satisfied: pkgutil-resolve-name>=1.3.10 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat==4.2.0) (1.3.10)\n",
      "Requirement already satisfied: importlib-metadata in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat==4.2.0) (4.11.4)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat==4.2.0) (0.19.2)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from importlib-resources>=1.4.0->jsonschema!=2.5.0,>=2.4->nbformat==4.2.0) (3.11.0)\n",
      "Installing collected packages: nbformat\n",
      "  Attempting uninstall: nbformat\n",
      "    Found existing installation: nbformat 5.7.0\n",
      "    Uninstalling nbformat-5.7.0:\n",
      "      Successfully uninstalled nbformat-5.7.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "nbconvert 7.2.6 requires nbformat>=5.1, but you have nbformat 4.2.0 which is incompatible.\n",
      "nbclient 0.7.2 requires nbformat>=5.1, but you have nbformat 4.2.0 which is incompatible.\n",
      "jupyter-server 1.23.3 requires nbformat>=5.2.0, but you have nbformat 4.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed nbformat-4.2.0\n",
      "\n",
      "                  __    __    __    __\n",
      "                 /  \\  /  \\  /  \\  /  \\\n",
      "                /    \\/    \\/    \\/    \\\n",
      "███████████████/  /██/  /██/  /██/  /████████████████████████\n",
      "              /  / \\   / \\   / \\   / \\  \\____\n",
      "             /  /   \\_/   \\_/   \\_/   \\    o \\__,\n",
      "            / _/                       \\_____/  `\n",
      "            |/\n",
      "        ███╗   ███╗ █████╗ ███╗   ███╗██████╗  █████╗\n",
      "        ████╗ ████║██╔══██╗████╗ ████║██╔══██╗██╔══██╗\n",
      "        ██╔████╔██║███████║██╔████╔██║██████╔╝███████║\n",
      "        ██║╚██╔╝██║██╔══██║██║╚██╔╝██║██╔══██╗██╔══██║\n",
      "        ██║ ╚═╝ ██║██║  ██║██║ ╚═╝ ██║██████╔╝██║  ██║\n",
      "        ╚═╝     ╚═╝╚═╝  ╚═╝╚═╝     ╚═╝╚═════╝ ╚═╝  ╚═╝\n",
      "\n",
      "        mamba (0.15.3) supported by @QuantStack\n",
      "\n",
      "        GitHub:  https://github.com/mamba-org/mamba\n",
      "        Twitter: https://twitter.com/QuantStack\n",
      "\n",
      "█████████████████████████████████████████████████████████████\n",
      "\n",
      "\n",
      "Looking for: ['html5lib==1.1']\n",
      "\n",
      "pkgs/main/linux-64       Using cache\n",
      "pkgs/main/noarch         Using cache\n",
      "pkgs/r/linux-64          Using cache\n",
      "pkgs/r/noarch            Using cache\n",
      "\n",
      "Pinned packages:\n",
      "  - python 3.7.*\n",
      "\n",
      "\n",
      "Transaction\n",
      "\n",
      "  Prefix: /home/jupyterlab/conda/envs/python\n",
      "\n",
      "  Updating specs:\n",
      "\n",
      "   - html5lib==1.1\n",
      "   - ca-certificates\n",
      "   - certifi\n",
      "   - openssl\n",
      "\n",
      "\n",
      "  Package         Version  Build         Channel                 Size\n",
      "───────────────────────────────────────────────────────────────────────\n",
      "  Install:\n",
      "───────────────────────────────────────────────────────────────────────\n",
      "\n",
      "\u001b[32m  + html5lib    \u001b[00m      1.1  pyhd3eb1b0_0  pkgs/main/noarch       91 KB\n",
      "\u001b[32m  + webencodings\u001b[00m    0.5.1  py37_1        pkgs/main/linux-64     19 KB\n",
      "\n",
      "  Summary:\n",
      "\n",
      "  Install: 2 packages\n",
      "\n",
      "  Total download: 110 KB\n",
      "\n",
      "───────────────────────────────────────────────────────────────────────\n",
      "\n",
      "Downloading  [======>                                  ] (00m:00s)  135.42 KB/s\n",
      "Extracting   [>                                                      ] (--:--) \n",
      "\u001b[2A\u001b[0KFinished webencodings                         (00m:00s)              19 KB    135 KB/s\n",
      "Downloading  [======>                                  ] (00m:00s)  135.42 KB/s\n",
      "Extracting   [>                                                      ] (--:--) \n",
      "Downloading  [======>                                  ] (00m:00s)  135.42 KB/s\n",
      "Extracting   [>                                                      ] (--:--) \n",
      "Downloading  [======>                                  ] (00m:00s)  135.42 KB/s\n",
      "Extracting   [>                                                      ] (--:--) \n",
      "Downloading  [=========================================] (00m:00s)  752.86 KB/s\n",
      "Extracting   [>                                                      ] (--:--) \n",
      "\u001b[2A\u001b[0KFinished html5lib                             (00m:00s)              91 KB    620 KB/s\n",
      "Downloading  [=========================================] (00m:00s)  752.86 KB/s\n",
      "Extracting   [>                                                      ] (--:--) \n",
      "Downloading  [=========================================] (00m:00s)  752.86 KB/s\n",
      "Extracting   [>                                                      ] (--:--) \n",
      "Downloading  [=========================================] (00m:00s)  752.86 KB/s\n",
      "Extracting   [====================>                    ] (00m:00s)        1 / 2\n",
      "Downloading  [=========================================] (00m:00s)  752.86 KB/s\n",
      "Extracting   [====================>                    ] (00m:00s)        1 / 2\n",
      "Downloading  [=========================================] (00m:00s)  752.86 KB/s\n",
      "Extracting   [=========================================] (00m:00s)        2 / 2\n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "Collecting lxml==4.6.4\n",
      "  Downloading lxml-4.6.4-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (6.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m63.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: lxml\n",
      "  Attempting uninstall: lxml\n",
      "    Found existing installation: lxml 4.9.1\n",
      "    Uninstalling lxml-4.9.1:\n",
      "      Successfully uninstalled lxml-4.9.1\n",
      "Successfully installed lxml-4.6.4\n"
     ]
    }
   ],
   "source": [
    "!pip install yfinance==0.1.67\n",
    "!mamba install bs4==4.10.0 -y\n",
    "!pip install nbformat==4.2.0\n",
    "#!pip install pandas==1.3.3\n",
    "#!pip install requests==2.26.0\n",
    "!mamba install html5lib==1.1 -y\n",
    "!pip install lxml==4.6.4\n",
    "#!pip install plotly==5.3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9860fee0-de38-4cd2-936b-7479745b0f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d6a13c-efae-4024-85e5-4edda1895c92",
   "metadata": {},
   "source": [
    "## Define Graphing Function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0e1b5f-6137-4d71-b130-5aabd2cfb7f5",
   "metadata": {},
   "source": [
    "In this section, we define the function `make_graph`. You don't have to know how the function works, you should only care about the inputs. It takes a dataframe with stock data (dataframe must contain Date and Close columns), a dataframe with revenue data (dataframe must contain Date and Revenue columns), and the name of the stock.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0dcaaa5e-e5ed-4337-beb4-134b5da043d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_graph(stock_data, revenue_data, stock):\n",
    "    fig = make_subplots(rows=2, cols=1, shared_xaxes=True, subplot_titles=(\"Historical Share Price\", \"Historical Revenue\"), vertical_spacing = .3)\n",
    "    stock_data_specific = stock_data[stock_data.Date <= '2021--06-14']\n",
    "    revenue_data_specific = revenue_data[revenue_data.Date <= '2021-04-30']\n",
    "    fig.add_trace(go.Scatter(x=pd.to_datetime(stock_data_specific.Date, infer_datetime_format=True), y=stock_data_specific.Close.astype(\"float\"), name=\"Share Price\"), row=1, col=1)\n",
    "    fig.add_trace(go.Scatter(x=pd.to_datetime(revenue_data_specific.Date, infer_datetime_format=True), y=revenue_data_specific.Revenue.astype(\"float\"), name=\"Revenue\"), row=2, col=1)\n",
    "    fig.update_xaxes(title_text=\"Date\", row=1, col=1)\n",
    "    fig.update_xaxes(title_text=\"Date\", row=2, col=1)\n",
    "    fig.update_yaxes(title_text=\"Price ($US)\", row=1, col=1)\n",
    "    fig.update_yaxes(title_text=\"Revenue ($US Millions)\", row=2, col=1)\n",
    "    fig.update_layout(showlegend=False,\n",
    "    height=900,\n",
    "    title=stock,\n",
    "    xaxis_rangeslider_visible=True)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbaa3d01-1420-4087-9d79-3a56522c1610",
   "metadata": {},
   "source": [
    "## Question 1: Use yfinance to Extract Stock Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d574fd10-1aab-4e46-a924-53d028709d24",
   "metadata": {},
   "source": [
    "Using the `Ticker` function enter the ticker symbol of the stock we want to extract data on to create a ticker object. The stock is Tesla and its ticker symbol is `TSLA`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "408e0d71-3e76-4731-8cb0-60e7efd7c9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tesla=yf.Ticker('TSLA')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c78686-b22b-490c-acac-b66d49024e46",
   "metadata": {},
   "source": [
    "Using the ticker object and the function `history` extract stock information and save it in a dataframe named `tesla_data`. Set the `period` parameter to `max` so we get information for the maximum amount of time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7f9763e4-9122-41ec-9443-a53343c59b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "tesla_data=Tesla.history(period =\"max\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15032e00-90d7-455e-adcd-a1eeec54d6e0",
   "metadata": {},
   "source": [
    "**Reset the index** using the `reset_index(inplace=True)` function on the tesla_data DataFrame and display the first five rows of the `tesla_data` dataframe using the `head` function. Take a screenshot of the results and code from the beginning of Question 1 to the results below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0123c47b-8378-4c7f-99be-80e571416ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tesla_data.reset_index(inplace= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94b5dab-a6f1-40eb-b836-0062988464db",
   "metadata": {},
   "source": [
    "## Question 2: Use Webscraping to Extract Tesla Revenue Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c4befd-c47e-4592-a72e-7c0b5c678068",
   "metadata": {},
   "source": [
    "Use the `requests` library to download the webpage https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0220EN-SkillsNetwork/labs/project/revenue.htm Save the text of the response as a variable named `html_data`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f65ee884-d9a1-424a-bcb2-bab7e3fbc53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "url=\" https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0220EN-SkillsNetwork/labs/project/revenue.htm\"\n",
    "tesla_data=requests.get(url).text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08fb22f-128a-4f99-8344-dd18d6279ab6",
   "metadata": {},
   "source": [
    "Parse the html data using `beautiful_soup`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "208b38b4-260c-4098-9b1e-9e88baed91c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(tesla_data, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2beb668c-ce60-4121-96fc-0aa47465f941",
   "metadata": {},
   "source": [
    "Using `BeautifulSoup` or the `read_html` function extract the table with `Tesla Quarterly Revenue` and store it into a dataframe named `tesla_revenue`. The dataframe should have columns `Date` and `Revenue`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d73b96-e834-49d0-a325-4341ab772ad8",
   "metadata": {},
   "source": [
    "<details><summary>Click here if you need help locating the table</summary>\n",
    "\n",
    "```\n",
    "    \n",
    "Below is the code to isolate the table, you will now need to loop through the rows and columns like in the previous lab\n",
    "    \n",
    "soup.find_all(\"tbody\")[1]\n",
    "    \n",
    "If you want to use the read_html function the table is located at index 1\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cd2a6e7c-8f63-48d6-b335-533af47912b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>$21,454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-06-30</td>\n",
       "      <td>$16,934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-03-31</td>\n",
       "      <td>$18,756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>$17,719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-09-30</td>\n",
       "      <td>$13,757</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  Revenue\n",
       "0  2022-09-30  $21,454\n",
       "1  2022-06-30  $16,934\n",
       "2  2022-03-31  $18,756\n",
       "3  2021-12-31  $17,719\n",
       "4  2021-09-30  $13,757"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tesla_revenue=pd.DataFrame(columns=[\"Date\",\"Revenue\"])\n",
    "for row in soup.find_all(\"tbody\")[1].find_all(\"tr\"):\n",
    "    col=row.find_all(\"td\")\n",
    "    date=col[0].text\n",
    "    revenue=col[1].text\n",
    "    tesla_revenue=tesla_revenue.append({\"Date\":date,\"Revenue\":revenue},ignore_index=True)\n",
    "    \n",
    "tesla_revenue.head()    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621993b9-01da-48e3-a3e3-d65364683bae",
   "metadata": {},
   "source": [
    "Execute the following line to remove the comma and dollar sign from the `Revenue` column. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a96aff4d-1999-4f8b-a2e2-a0a9d15f900f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "tesla_revenue[\"Revenue\"] = tesla_revenue['Revenue'].str.replace(',|\\$',\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e23a47-3512-489a-b2da-7d596cee444d",
   "metadata": {},
   "source": [
    "Execute the following lines to remove an null or empty strings in the Revenue column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3f14fcdc-450c-4fba-82da-a56ec62ac81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tesla_revenue.dropna(inplace=True)\n",
    "\n",
    "tesla_revenue = tesla_revenue[tesla_revenue['Revenue'] != \"\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64f6be4-8b4f-4077-b7dc-03ce2c2df456",
   "metadata": {},
   "source": [
    "Display the last 5 row of the `tesla_revenue` dataframe using the `tail` function. Take a screenshot of the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3676dbd9-97ce-4fb8-945c-ca96db5d28d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>2010-09-30</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2010-06-30</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>2010-03-31</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>2009-09-30</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>2009-06-30</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date Revenue\n",
       "48  2010-09-30      31\n",
       "49  2010-06-30      28\n",
       "50  2010-03-31      21\n",
       "52  2009-09-30      46\n",
       "53  2009-06-30      27"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tesla_revenue.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef322a4-e492-4e0e-a514-5122180f8654",
   "metadata": {},
   "source": [
    "## Question 3: Use yfinance to Extract Stock Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662635b8-6df0-4db5-a536-a82e6dff05dc",
   "metadata": {},
   "source": [
    "Using the `Ticker` function enter the ticker symbol of the stock we want to extract data on to create a ticker object. The stock is GameStop and its ticker symbol is `GME`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f45e0206-d410-44f7-869f-f5e8d6985de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "GameStop = yf.Ticker('GME')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9983cb-a323-4f8e-8ff6-e5af19e10286",
   "metadata": {},
   "source": [
    "Using the ticker object and the function `history` extract stock information and save it in a dataframe named `gme_data`. Set the `period` parameter to `max` so we get information for the maximum amount of time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5da839c4-31ae-49aa-ace9-fdebade2eb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gme_data=GameStop.history(period='max')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1620f225-e2d6-4ba8-ac99-9e701fdcdea0",
   "metadata": {},
   "source": [
    "**Reset the index** using the `reset_index(inplace=True)` function on the gme_data DataFrame and display the first five rows of the `gme_data` dataframe using the `head` function. Take a screenshot of the results and code from the beginning of Question 3 to the results below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e5dbf4a7-d32e-412b-b6c5-1b22fd5944ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "gme_data.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96df5f96-275e-47fb-9f39-509e09adbab6",
   "metadata": {},
   "source": [
    "## Question 4: Use Webscraping to Extract GME Revenue Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40ea356-9393-4bf7-a67f-f95741863ad7",
   "metadata": {},
   "source": [
    "https://finance.yahoo.com/news/gamestop-gme-stock-sinks-market-230011154.html?guccounter=1&guce_referrer=aHR0cHM6Ly93d3cuZ29vZ2xlLmNvbS8&guce_referrer_sig=AQAAAHveQKwploTQmGMgN4sn6MN4VcLNQUhZ5KEfhjfUWDx7qUkDGiX7CeMk9cgE1XMLxJmNyJxBho1sYCMIf5Rti2V8AHArdM_9ZIlfyELWQPyUDtqujPnEMXd6j8beaN0SNJhRBS2f47ZaY11LASelRj4b99uTGegYt-b4mQLSxexgUse the `requests` library to download the webpage https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0220EN-SkillsNetwork/labs/project/stock.html. Save the text of the response as a variable named `html_data`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "35ddd411-d1c1-4a06-9f2e-b1a31566ef2c",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_69/3890532050.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mhtml_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Date\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Revenue\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tbody\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tr\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mcol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"td\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mdate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "url=\"https://finance.yahoo.com/news/gamestop-gme-stock-sinks-market-230011154.html?guccounter=1&guce_referrer=aHR0cHM6Ly93d3cuZ29vZ2xlLmNvbS8&guce_referrer_sig=AQAAAHveQKwploTQmGMgN4sn6MN4VcLNQUhZ5KEfhjfUWDx7qUkDGiX7CeMk9cgE1XMLxJmNyJxBho1sYCMIf5Rti2V8AHArdM_9ZIlfyELWQPyUDtqujPnEMXd6j8beaN0SNJhRBS2f47ZaY11LASelRj4b99uTGegYt-b4mQLSxexg\"\n",
    "data=requests.get(url).text\n",
    "soup=BeautifulSoup(data,'html.parser')\n",
    "\n",
    "html_data=pd.DataFrame(columns=[\"Date\",\"Revenue\"])\n",
    "for row in soup.find_all(\"tbody\")[1].find_all(\"tr\"):\n",
    "    col=row.find_all(\"td\")\n",
    "    date=col[0].text\n",
    "    revenue=col[1].text\n",
    "    html_data=html_data.append({\"Date\":date,\"Revenue\":revenue},ignore_index=True)\n",
    "    \n",
    "html_data.head()    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18de3ace-3412-47aa-ae7f-97d486debff9",
   "metadata": {},
   "source": [
    "Parse the html data using `beautiful_soup`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c932e23d-cd21-4e85-afc8-7e3193134d74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2b8e8a88-b39e-4ca0-82e7-d833cf090e85",
   "metadata": {},
   "source": [
    "Using `BeautifulSoup` or the `read_html` function extract the table with `GameStop Quarterly Revenue` and store it into a dataframe named `gme_revenue`. The dataframe should have columns `Date` and `Revenue`. Make sure the comma and dollar sign is removed from the `Revenue` column using a method similar to what you did in Question 2.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7f53d6-b641-4f2a-b7c0-09946f07300f",
   "metadata": {},
   "source": [
    "<details><summary>Click here if you need help locating the table</summary>\n",
    "\n",
    "```\n",
    "    \n",
    "Below is the code to isolate the table, you will now need to loop through the rows and columns like in the previous lab\n",
    "    \n",
    "soup.find_all(\"tbody\")[1]\n",
    "    \n",
    "If you want to use the read_html function the table is located at index 1\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0435b643-007e-4713-bf52-f3bc2d3fc611",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bf5f0a15-d2bc-48e0-9899-4020ed99dbd7",
   "metadata": {},
   "source": [
    "Display the last five rows of the `gme_revenue` dataframe using the `tail` function. Take a screenshot of the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce8dbe5-c305-48f4-aecb-487126ac37b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9f78c13c-8932-446f-bb66-7f278b559d3e",
   "metadata": {},
   "source": [
    "## Question 5: Plot Tesla Stock Graph\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f149575a-faf8-41bc-8c35-7b17b7928d89",
   "metadata": {},
   "source": [
    "Use the `make_graph` function to graph the Tesla Stock Data, also provide a title for the graph. The structure to call the `make_graph` function is `make_graph(tesla_data, tesla_revenue, 'Tesla')`. Note the graph will only show data upto June 2021.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "35bf663e-3531-43b2-9447-69500a4fb38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "url=\" https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0220EN-SkillsNetwork/labs/project/revenue.htm\"\n",
    "tesla_data=requests.get(url).text\n",
    "soup = BeautifulSoup(tesla_data, 'html.parser')\n",
    "\n",
    "tesla_revenue=pd.DataFrame(columns=[\"Date\",\"Revenue\"])\n",
    "for row in soup.find_all(\"tbody\")[1].find_all(\"tr\"):\n",
    "    col=row.find_all(\"td\")\n",
    "    date=col[0].text\n",
    "    revenue=col[1].text\n",
    "    tesla_revenue=tesla_revenue.append({\"Date\":date,\"Revenue\":revenue},ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "def make_graph(tesla_data,tesla_revenue,TSLA):\n",
    "    fig = make_subplots(rows=2, cols=1, shared_xaxes=True, subplot_titles=(\"Historical Revenue\"), vertical_spacing = .3)\n",
    "    \n",
    "    revenue_data_specific = tesla_revenue[tesla_revenue.Date <= '2021-04-30']\n",
    "\n",
    "    fig.add_trace(go.Scatter(x=pd.to_datetime(revenue_data_specific.Date, infer_datetime_format=True), y=revenue_data_specific.Revenue.astype(\"float\"), name=\"Revenue\"), row=2, col=1)\n",
    "    \n",
    "    fig.update_xaxes(title_text=\"Date\", row=1, col=1)\n",
    "    \n",
    "    fig.update_yaxes(title_text=\"Revenue ($US Millions)\", row=2, col=1)\n",
    "    fig.update_layout(showlegend=False,\n",
    "    height=900,\n",
    "    title=stock,\n",
    "    xaxis_rangeslider_visible=True)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0241bee-799c-4d33-8a95-0d5572066f14",
   "metadata": {},
   "source": [
    "## Change Log\n",
    "\n",
    "| Date (YYYY-MM-DD) | Version | Changed By    | Change Description        |\n",
    "| ----------------- | ------- | ------------- | ------------------------- |\n",
    "| 2022-02-28        | 1.2     | Lakshmi Holla | Changed the URL of GameStop |\n",
    "| 2020-11-10        | 1.1     | Malika Singla | Deleted the Optional part |\n",
    "| 2020-08-27        | 1.0     | Malika Singla | Added lab to GitLab       |\n",
    "\n",
    "<hr>\n",
    "\n",
    "## <h3 align=\"center\"> © IBM Corporation 2020. All rights reserved. <h3/>\n",
    "\n",
    "<p>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
